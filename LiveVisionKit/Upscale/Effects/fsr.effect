//NOTE: need to use modified version for compatibility
#include "ffx_a_mod.h"

//=====================================================================================
//		OBS Parameters & Callbacks
//=====================================================================================

uniform float4x4 ViewProj;
uniform texture2d image; 

//=====================================================================================
//		FSR Parameters & Callbacks
//=====================================================================================

// NOTE: We use AF* instead of the original FSR AU*
// uniforms as these aren't supported in the HLSL-GLSL
// conversion performed by OBS. See modified FSR files
// for more information on unsupported functionality. 
uniform AF2 output_size;
uniform AF4 easu_const_0;
uniform AF4 easu_const_1;
uniform AF4 easu_const_2;
uniform AF4 easu_const_3;
uniform AF4 rcas_const_0;

sampler_state PointSampler 
{
    Filter      = Point; 
    AddressU    = Clamp;
    AddressV    = Clamp;
};

AF4 FsrEasuRF(AF2 p)
{
    // Four texel gather operations such as GatherRed (HLSL) or textureGather.r (GLSL)
    // are not supported by OBS So we are forced to mimic using point sampling. 
    // For a given point p in normalized texture coordinates. We want to grab neighbouring
    // texels x, y, z, and w in the listed order.
    //
    //                                  +---+---+
    //                                  | w | z |
    //                                  +--(p)--+
    //                                  | x | y |
    //                                  +---+---+
    //
    // The size of a texel is pre-computed by the FsrEasuCon call and stored within the .xy
    // of con1. This is called on the CPU side and passed in via uniform to easu_const_1. 
    // To get the normalized texture coordinates for each required texel, we then offset 
    // point p by half the texel size using addition/subtraction as necessary.
    return AF4(
        image.Sample(PointSampler, AF2(p.x - 0.5 * easu_const_1.x, p.y + 0.5 * easu_const_1.y)).r,
        image.Sample(PointSampler, AF2(p.x + 0.5 * easu_const_1.x, p.y + 0.5 * easu_const_1.y)).r,
        image.Sample(PointSampler, AF2(p.x + 0.5 * easu_const_1.x, p.y - 0.5 * easu_const_1.y)).r,
        image.Sample(PointSampler, AF2(p.x - 0.5 * easu_const_1.x, p.y - 0.5 * easu_const_1.y)).r
    );
}

AF4 FsrEasuGF(AF2 p)
{
    // Four texel gather operations such as GatherGreen (HLSL) or textureGather.r (GLSL)
    // are not supported by OBS So we are forced to mimic using point sampling. 
    // For a given point p in normalized texture coordinates. We want to grab neighbouring
    // texels x, y, z, and w in the listed order.
    //
    //                                  +---+---+
    //                                  | w | z |
    //                                  +--(p)--+
    //                                  | x | y |
    //                                  +---+---+
    //
    // The size of a texel is pre-computed by the FsrEasuCon call and stored within the .xy
    // of con1. This is called on the CPU side and passed in via uniform to easu_const_1. 
    // To get the normalized texture coordinates for each required texel, we then offset 
    // point p by half the texel size using addition/subtraction as necessary.
    return AF4(
        image.Sample(PointSampler, AF2(p.x - 0.5 * easu_const_1.x, p.y + 0.5 * easu_const_1.y)).g,
        image.Sample(PointSampler, AF2(p.x + 0.5 * easu_const_1.x, p.y + 0.5 * easu_const_1.y)).g,
        image.Sample(PointSampler, AF2(p.x + 0.5 * easu_const_1.x, p.y - 0.5 * easu_const_1.y)).g,
        image.Sample(PointSampler, AF2(p.x - 0.5 * easu_const_1.x, p.y - 0.5 * easu_const_1.y)).g
    );
}

AF4 FsrEasuBF(AF2 p)
{
    // Four texel gather operations such as GatherBlue (HLSL) or textureGather.r (GLSL)
    // are not supported by OBS So we are forced to mimic using point sampling. 
    // For a given point p in normalized texture coordinates. We want to grab neighbouring
    // texels x, y, z, and w in the listed order.
    //
    //                                  +---+---+
    //                                  | w | z |
    //                                  +--(p)--+
    //                                  | x | y |
    //                                  +---+---+
    //
    // The size of a texel is pre-computed by the FsrEasuCon call and stored within the .xy
    // of con1. This is called on the CPU side and passed in via uniform to easu_const_1. 
    // To get the normalized texture coordinates for each required texel, we then offset 
    // point p by half the texel size using addition/subtraction as necessary.
    return AF4(
        image.Sample(PointSampler, AF2(p.x - 0.5 * easu_const_1.x, p.y + 0.5 * easu_const_1.y)).b,
        image.Sample(PointSampler, AF2(p.x + 0.5 * easu_const_1.x, p.y + 0.5 * easu_const_1.y)).b,
        image.Sample(PointSampler, AF2(p.x + 0.5 * easu_const_1.x, p.y - 0.5 * easu_const_1.y)).b,
        image.Sample(PointSampler, AF2(p.x - 0.5 * easu_const_1.x, p.y - 0.5 * easu_const_1.y)).b
    );
}

AF4 FsrRcasLoadF(ASU2 p)
{   
    // Texel gather operations such as .Load (HLSL( or texelFetch (GLSL)
    // are not supported by the OBS HLSL-GLSL converter So we are forced to mimic 
    // this functionality using a simple point sample.

    //NOTE: Addition of small value such as 0.1 removes blocking artifacts caused by Point 
    // sampling and makes output more similar to performing a proper .Load or texelFetch. 
    return image.Sample(PointSampler, (AF2(p) + AF2(0.1, 0.1)) / output_size);
}

void FsrRcasInputF(inout AF1 r, inout AF1 g, inout AF1 b)
{
    // NOT USED
}

//NOTE: need to use modified version for compatibility
#include "ffx_fsr1_mod.h"

//=====================================================================================
//		VERTEX SHADER
//=====================================================================================

struct VSData 
{
    float4 pos : POSITION;
    float2 uv  : TEXCOORD0;
};

VSData VSMain(VSData vs_in)
{
    VSData vs_out;
    vs_out.pos = mul(float4(vs_in.pos.xyz, 1.0), ViewProj);
    vs_out.uv  = vs_in.uv;
    return vs_out;
}

//=====================================================================================
//		PIXEL SHADER
//=====================================================================================

float4 PSEASUMain(VSData vs_in) : TARGET
{
    AF3 out_col = AF3(0, 0, 0);
    AF2 out_pos = floor(vs_in.uv * output_size.xy); 

    FsrEasuF(out_col, out_pos, easu_const_0, easu_const_1, easu_const_2, easu_const_3);


    return float4(out_col, 1.0);
}

float4 PSRCASMain(VSData vs_in) : TARGET
{
    AF3 out_col = AF3(0, 0, 0);
    AF2 out_pos = floor(vs_in.uv * output_size.xy);
   
    FsrRcasF(out_col.r, out_col.g, out_col.b, out_pos, rcas_const_0);

    return float4(out_col, 1.0);
}

//=====================================================================================
//		TECHNIQUES
//=====================================================================================

technique EASU
{
    pass
    {
        vertex_shader = VSMain(vs_in);
        pixel_shader  = PSEASUMain(vs_in);
    }
};

technique RCAS
{
    pass
    {
        vertex_shader = VSMain(vs_in);
        pixel_shader  = PSRCASMain(vs_in);
    }
};